Agent 'DDPG-TD3_003' initialized with following params:
  TD3=True
  RANDOM_WARM_UP=1024
  BUFFER_SIZE=1000000
  BATCH_SIZE=512
  GAMMA=0.99
  TAU=0.005
  name='DDPG-TD3_003'
  MIN_EXPL_NOISE=0.03
  MIN_POLI_NOISE=0.05
  state_size=24
  actor_layer_noise=0
  actor_layer_reg=0
  actor_batch_norm=True
  actor_activation='relu'
  actor_lr=0.0001
  actor_custom_init='custom'
  critic_layer_reg=0
  critic_layer_noise=0
  critic_batch_norm=False
  critic_state_batch_norm=True
  critic_activation='relu'
  critic_lr=0.0001
  critic_clip_norm=1
  critic_custom_init='custom'
  critic_simple=True
  action_size=4
  policy_update_freq=2
  policy_noise=0.2
  noise_clip=0.5
  explor_noise=0.1
  max_action=1
  min_action=-1
  train_iters=0
  actor_updates=0
  step_counter=0
  steps_to_train_counter=0
  skip_update_timer=0

__________________________________________________________________________________________________
Agent 'DDPG-TD3_005' initialized with following params:
  TD3=True
  RANDOM_WARM_UP=1024
  BUFFER_SIZE=1000000
  BATCH_SIZE=512
  GAMMA=0.99
  TAU=0.005
  name='DDPG-TD3_005'
  MIN_EXPL_NOISE=0.03
  MIN_POLI_NOISE=0.05
  state_size=24
  actor_layer_noise=0
  actor_layer_reg=0
  actor_batch_norm=False
  actor_activation='relu'
  actor_lr=0.0001
  actor_custom_init='custom'
  critic_layer_reg=0.01
  critic_layer_noise=0
  critic_batch_norm=False
  critic_state_batch_norm=True
  critic_activation='relu'
  critic_lr=0.0001
  critic_clip_norm=1
  critic_custom_init='custom'
  critic_simple=True
  action_size=4
  policy_update_freq=2
  policy_noise=0.2
  noise_clip=0.5
  explor_noise=0.1
  max_action=1
  min_action=-1
  train_iters=0
  actor_updates=0
  step_counter=0
  steps_to_train_counter=0
  skip_update_timer=0

__________________________________________________________________________________________________
Agent 'DDPG-TD3_007' initialized with following params:
  TD3=True
  RANDOM_WARM_UP=1024
  BUFFER_SIZE=1000000
  BATCH_SIZE=512
  GAMMA=0.99
  TAU=0.005
  name='DDPG-TD3_007'
  MIN_EXPL_NOISE=0.03
  MIN_POLI_NOISE=0.05
  state_size=24
  actor_layer_noise=0
  actor_layer_reg=0
  actor_batch_norm=False
  actor_activation='relu'
  actor_lr=0.0001
  actor_custom_init='custom'
  critic_layer_reg=0
  critic_layer_noise=0
  critic_batch_norm=False
  critic_state_batch_norm=True
  critic_activation='relu'
  critic_lr=0.0001
  critic_clip_norm=1
  critic_custom_init='custom'
  critic_simple=True
  action_size=4
  policy_update_freq=2
  policy_noise=0.2
  noise_clip=0.5
  explor_noise=0.1
  max_action=1
  min_action=-1
  train_iters=0
  actor_updates=0
  step_counter=0
  steps_to_train_counter=0
  skip_update_timer=0

